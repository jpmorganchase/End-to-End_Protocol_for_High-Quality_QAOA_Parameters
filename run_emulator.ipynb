{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from time import sleep\n",
    "from typing import Any, Literal\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from qokit.maxcut import maxcut_obj, get_adjacency_matrix\n",
    "from qokit.qaoa_objective_maxcut import get_qaoa_maxcut_objective\n",
    "from qokit.qaoa_objective_portfolio import get_qaoa_portfolio_objective\n",
    "from qokit.utils import precompute_energies\n",
    "from qokit.portfolio_optimization import portfolio_brute_force\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def create_portfolio_instance(\n",
    "    start_date: str = \"2015-01-01\",\n",
    "    end_date: str = \"2019-12-31\",\n",
    "    num_assets: int = 0,\n",
    "    return_dtype: str = \"numpy\",\n",
    "    log_returns: bool = False,\n",
    "    tickers: list | None = None,\n",
    "    sort_by_avg_volume: bool = False,\n",
    "    seed: int = 42,\n",
    ") -> (\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "    | tuple[pd.core.frame.DataFrame, pd.core.frame.DataFrame]\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------------\n",
    "        start_date (str): The starting date\n",
    "        end_date (str): The ending date\n",
    "        num_assets (int): The number of assets\n",
    "\n",
    "\n",
    "        Optional:\n",
    "        return_dtype (str): The return datatype for the correlation matrix\n",
    "                     This is either numpy or panda\n",
    "\n",
    "        tickers (list): The list of ticker symbols. If this is not provided, you will get\n",
    "        the targets and correlation for the random tickers and you can read the\n",
    "        symbols via accessing the correlation as a pandas dataframe\n",
    "\n",
    "        log_returns: If we want the log returns instead of just returns\n",
    "\n",
    "    -------------------\n",
    "    Returns\n",
    "    ---------\n",
    "    List(returns, correlation) : type List(np.array, np.array or pd.dataframe)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (\n",
    "        return_dtype == \"numpy\"\n",
    "        or return_dtype == \"np\"\n",
    "        or return_dtype == \"pd\"\n",
    "        or return_dtype == \"pandas\"\n",
    "    ):\n",
    "        pass\n",
    "    else:\n",
    "        # print(return_dtype)\n",
    "        raise ValueError(\n",
    "            \"The return dtype should be either (numpy) or (np) or pandas or (pd)\"\n",
    "        )\n",
    "\n",
    "    if tickers is None:\n",
    "        # If the user doesn't provide the ticker symbols, we sort by average trading volume and just\n",
    "        # give the data for the number of assets provided\n",
    "\n",
    "        # Download data for the time period\n",
    "        sp500_tickers = pd.read_html(\n",
    "            \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "        )[0]\n",
    "\n",
    "        ticker_symbols = sp500_tickers[\"Symbol\"].tolist()\n",
    "\n",
    "        if num_assets > 0 and not sort_by_avg_volume:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            random_tickers = rng.choice(\n",
    "                len(ticker_symbols), size=num_assets, replace=False\n",
    "            )\n",
    "\n",
    "            top_N_ticker_symbols = np.array(ticker_symbols)[random_tickers].tolist()\n",
    "\n",
    "        else:\n",
    "            top_N_ticker_symbols = ticker_symbols\n",
    "\n",
    "        # Retrieve historical price data for each ticker symbol\n",
    "        stock_data = {}\n",
    "\n",
    "        invalid_ticker_symbols = []\n",
    "\n",
    "        for symbol in top_N_ticker_symbols:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "            if data.empty:\n",
    "                ### Removing the ticker symbols that are invalid\n",
    "                invalid_ticker_symbols.append(symbol)\n",
    "            else:\n",
    "                stock_data[symbol] = data\n",
    "\n",
    "        if sort_by_avg_volume or num_assets == 0:\n",
    "            # Calculate average trading volume for each stock\n",
    "            average_volumes = {}\n",
    "            for symbol, data in stock_data.items():\n",
    "                average_volume = data[\"Volume\"].mean()\n",
    "                average_volumes[symbol] = average_volume\n",
    "\n",
    "            # Sort the stocks based on average trading volume\n",
    "            sorted_stocks = sorted(\n",
    "                average_volumes.items(), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "\n",
    "            # Extract the ticker symbols from the sorted list\n",
    "            ticker_list = [tick[0] for tick in sorted_stocks]\n",
    "\n",
    "            if num_assets > 0:\n",
    "                top_N_ticker_symbols = ticker_list[:num_assets]\n",
    "\n",
    "    ### This is if we are given a set of tickers\n",
    "    ### Then just download data for these, and compute correlation matrices and return vector\n",
    "\n",
    "    else:\n",
    "        num_assets = len(tickers)\n",
    "        # Retrieve historical price data for each ticker symbol\n",
    "        stock_data = {}\n",
    "\n",
    "        invalid_ticker_symbols = []\n",
    "\n",
    "        for symbol in tickers:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            while True:\n",
    "                data = ticker.history(start=start_date, end=end_date)\n",
    "                if data.empty:\n",
    "                    sleep(2)\n",
    "                    continue\n",
    "                else:\n",
    "                    stock_data[symbol] = data\n",
    "\n",
    "        top_N_ticker_symbols = tickers\n",
    "\n",
    "    top_N_ticker_symbols = list(stock_data.keys())\n",
    "\n",
    "    ### List of dataframes with the closing prices\n",
    "    list_df_close = [stock_data[symbol][\"Close\"] for symbol in top_N_ticker_symbols]\n",
    "\n",
    "    df_close = pd.concat(list_df_close, axis=1, keys=top_N_ticker_symbols)\n",
    "\n",
    "    ### Drop the ones with rows with NaN values\n",
    "    df_close = df_close.dropna(axis=1)\n",
    "    df_close = df_close.dropna(axis=0)\n",
    "\n",
    "    if not log_returns:\n",
    "        df_returns = df_close.pct_change()  # .dropna( )\n",
    "\n",
    "        #### Drop the first row since we have NaN's\n",
    "        df_returns = df_returns.iloc[1:]\n",
    "\n",
    "        df_mean_returns = df_returns.mean(axis=0)\n",
    "\n",
    "        correlation_matrix = df_returns.corr()\n",
    "\n",
    "        if return_dtype in (\"pandas\", \"pd\"):\n",
    "            return [df_mean_returns, correlation_matrix]\n",
    "        else:\n",
    "            return [df_mean_returns.to_numpy(), correlation_matrix.to_numpy()]\n",
    "\n",
    "    elif log_returns:\n",
    "        df_logreturns = np.log(df_close / df_close.shift(1)).dropna()\n",
    "        df_meanlog_returns = df_logreturns.mean(axis=0)\n",
    "\n",
    "        correlation_matrix = df_logreturns.corr()\n",
    "\n",
    "        if return_dtype in (\"pandas\", \"pd\"):\n",
    "            return [df_meanlog_returns, correlation_matrix]\n",
    "\n",
    "        else:\n",
    "            return [df_meanlog_returns.to_numpy(), correlation_matrix.to_numpy()]\n",
    "\n",
    "\n",
    "def get_data(N, seed=1, real=False):\n",
    "    \"\"\"\n",
    "    load portofolio data from qiskit-finance (Yahoo)\n",
    "    https://github.com/Qiskit/qiskit-finance/blob/main/docs/tutorials/11_time_series.ipynb\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "\n",
    "    from qiskit_finance.data_providers import RandomDataProvider, YahooDataProvider\n",
    "\n",
    "    tickers = []\n",
    "    for i in range(N):\n",
    "        tickers.append(\"t\" + str(i))\n",
    "    if real is False:\n",
    "        data = RandomDataProvider(\n",
    "            tickers=tickers,\n",
    "            start=datetime.datetime(2016, 1, 1),\n",
    "            end=datetime.datetime(2016, 1, 30),\n",
    "            seed=seed,\n",
    "        )\n",
    "    else:\n",
    "        stock_symbols = [\n",
    "            \"AAPL\",\n",
    "            \"GOOGL\",\n",
    "            \"AMZN\",\n",
    "            \"MSFT\",\n",
    "            \"TSLA\",\n",
    "            \"NFLX\",\n",
    "            \"NVDA\",\n",
    "            \"JPM\",\n",
    "            \"V\",\n",
    "            \"JNJ\",\n",
    "            \"WMT\",\n",
    "            \"PG\",\n",
    "            \"MA\",\n",
    "            \"UNH\",\n",
    "            \"HD\",\n",
    "            \"DIS\",\n",
    "            \"BRK-B\",\n",
    "            \"VZ\",\n",
    "            \"KO\",\n",
    "            \"MRK\",\n",
    "            \"INTC\",\n",
    "            \"CMCSA\",\n",
    "            \"PEP\",\n",
    "            \"PFE\",\n",
    "            \"CSCO\",\n",
    "            \"XOM\",\n",
    "            \"BA\",\n",
    "            \"MCD\",\n",
    "            \"ABBV\",\n",
    "            \"IBM\",\n",
    "            \"GE\",\n",
    "            \"MMM\",\n",
    "        ]\n",
    "\n",
    "        # switch to Atithi's implementation\n",
    "        # rng = np.random.default_rng(seed)\n",
    "        # date = rng.integers(0, 60)\n",
    "\n",
    "        date = seed\n",
    "        year = 2015 + date // 12\n",
    "        month = date % 12 + 1\n",
    "        start_date = f\"{year}-{month}-01\"\n",
    "        end_date = f\"{year}-{month}-28\"\n",
    "        return create_portfolio_instance(\n",
    "            start_date,\n",
    "            end_date,\n",
    "            0,\n",
    "            log_returns=True,\n",
    "            seed=seed,\n",
    "            # tickers=[\n",
    "            #     stock_symbols[i] for i in rng.choice(len(stock_symbols), size=N, replace=False)\n",
    "            # ],\n",
    "            tickers=stock_symbols[:N],\n",
    "        )\n",
    "\n",
    "        # data = YahooDataProvider(\n",
    "        #     tickers=stock_symbols[:N],\n",
    "        #     start=datetime.datetime(2020, 1, 1),\n",
    "        #     end=datetime.datetime(2020, 1, 30),\n",
    "        #     # end=datetime.datetime(2021, 1, 1),\n",
    "        # )\n",
    "\n",
    "    data.run()\n",
    "    # use get_period_return_mean_vector & get_period_return_covariance_matrix to get return!\n",
    "    # https://github.com/Qiskit/qiskit-finance/blob/main/docs/tutorials/01_portfolio_optimization.ipynb\n",
    "    means = data.get_period_return_mean_vector()\n",
    "    cov = data.get_period_return_covariance_matrix()\n",
    "    return means, cov\n",
    "\n",
    "\n",
    "def get_real_problem(N, K, q, seed=1, pre=False):\n",
    "    po_problem = {}\n",
    "    po_problem[\"N\"] = N\n",
    "    po_problem[\"K\"] = K\n",
    "    po_problem[\"q\"] = q\n",
    "    po_problem[\"real\"] = True\n",
    "    po_problem[\"means\"], po_problem[\"cov\"] = get_data(N, seed, real=True)\n",
    "    po_problem[\"pre\"] = pre\n",
    "    scale = 1\n",
    "    if pre == \"constant\":\n",
    "        scale = abs(1 / sum(po_problem[\"means\"]))\n",
    "    elif np.isscalar(pre):\n",
    "        scale = pre\n",
    "\n",
    "    po_problem[\"scale\"] = scale\n",
    "    po_problem[\"means\"] = scale * po_problem[\"means\"]\n",
    "    po_problem[\"cov\"] = scale * po_problem[\"cov\"]\n",
    "\n",
    "    return po_problem\n",
    "\n",
    "\n",
    "def load_problem(\n",
    "    problem: Literal[\"maxcut\", \"po\"], n: int, seed: int\n",
    ") -> tuple[dict[str, Any] | nx.Graph, NDArray[np.float_]]:\n",
    "    if problem == \"maxcut\":\n",
    "        return load_maxcut_problem(n, seed)\n",
    "    if problem == \"po\":\n",
    "        return load_po_problem(n, seed)\n",
    "    raise ValueError(f\"Problem {problem} not recognized\")\n",
    "\n",
    "\n",
    "def sample_gaussian_mixture(\n",
    "    num_samples: int, components: Sequence[dict[str, float]], seed: int\n",
    ") -> NDArray[np.float_]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        component = rng.choice(components, p=[c[\"weight\"] for c in components])\n",
    "        sample = rng.normal(component[\"mean\"], component[\"std_dev\"])\n",
    "        samples.append(sample)\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def load_maxcut_problem(n: int, seed: int) -> tuple[nx.Graph, NDArray[np.float_]]:\n",
    "    g = nx.random_regular_graph(3, n, seed)\n",
    "\n",
    "    # Define the parameters for the Gaussian components\n",
    "    component1 = {\"mean\": 0, \"std_dev\": 1, \"weight\": 0.5}\n",
    "    component2 = {\"mean\": 5, \"std_dev\": 2, \"weight\": 0.3}\n",
    "    component3 = {\"mean\": 10, \"std_dev\": 1, \"weight\": 0.2}\n",
    "    components = [component1, component2, component3]\n",
    "    weights = sample_gaussian_mixture(3 * n // 2, components, seed)\n",
    "    # generate random weights\n",
    "    # weights = np.random.uniform(0, 10, g.number_of_edges())\n",
    "    # rescale following the rule in Eq. 6 of https://arxiv.org/pdf/2305.15201.pdf\n",
    "    weights = weights / np.sqrt(np.mean(weights**2))\n",
    "\n",
    "    for i, (w, v) in enumerate(g.edges):\n",
    "        g.edges[w, v][\"weight\"] = weights[i]\n",
    "\n",
    "    return g, precompute_energies(partial(maxcut_obj, w=get_adjacency_matrix(g)), n)\n",
    "\n",
    "\n",
    "def load_po_problem(n, seed):\n",
    "    k = n // 2\n",
    "    po_problem = get_real_problem(n, k, 0.5, seed, pre=1)\n",
    "    means_in_spins = np.array(\n",
    "        [\n",
    "            po_problem[\"means\"][i] - po_problem[\"q\"] * np.sum(po_problem[\"cov\"][i, :])\n",
    "            for i in range(len(po_problem[\"means\"]))\n",
    "        ]\n",
    "    )\n",
    "    scale = 1 / (\n",
    "        np.sqrt(np.mean(((po_problem[\"q\"] * po_problem[\"cov\"]) ** 2).flatten()))\n",
    "        + np.sqrt(np.mean((means_in_spins**2).flatten()))\n",
    "    )\n",
    "    po_problem[\"scale\"] = scale\n",
    "    po_problem[\"means\"] = scale * po_problem[\"means\"]\n",
    "    po_problem[\"cov\"] = scale * po_problem[\"cov\"]\n",
    "    (\n",
    "        min_constrained,\n",
    "        min_x,\n",
    "        max_constrained,\n",
    "        max_x,\n",
    "        mean_constrained,\n",
    "    ) = portfolio_brute_force(po_problem, True)\n",
    "    po_problem[\"feasible_min\"] = min_constrained\n",
    "    po_problem[\"feasible_max\"] = max_constrained\n",
    "    po_problem[\"feasible_min_x\"] = min_x\n",
    "    po_problem[\"feasible_max_x\"] = max_x\n",
    "    po_problem[\"feasible_mean\"] = mean_constrained\n",
    "\n",
    "    return po_problem, None\n",
    "\n",
    "\n",
    "def get_evaluate_energy(\n",
    "    problem: dict[str, Any] | nx.Graph,\n",
    "    precomputed_energies: NDArray[np.float_],\n",
    "    p: int,\n",
    "    objective: str = \"expectation\",\n",
    "    simulator: str = \"auto\",\n",
    ") -> Callable:\n",
    "    if isinstance(problem, nx.Graph):\n",
    "        beta_scaling = 1 / 4\n",
    "        func = get_qaoa_maxcut_objective(\n",
    "            problem.number_of_nodes(),\n",
    "            p,\n",
    "            problem,\n",
    "            precomputed_energies,\n",
    "            objective=objective,\n",
    "            simulator=simulator,\n",
    "        )\n",
    "    else:\n",
    "        beta_scaling = 1 / 8\n",
    "        func = get_qaoa_portfolio_objective(\n",
    "            problem,\n",
    "            p,\n",
    "            precomputed_energies=precomputed_energies,\n",
    "            objective=objective,\n",
    "            simulator=simulator,\n",
    "        )\n",
    "\n",
    "    def f(params):\n",
    "        params = np.array(params)\n",
    "        params[len(params) // 2 :] *= beta_scaling\n",
    "        return func(params)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def eval_point(point, eval_func, optimal_metric, sense):\n",
    "    mean = eval_func(point)\n",
    "    ar = (\n",
    "        sense\n",
    "        * (mean - optimal_metric[int((sense + 1) / 2)])\n",
    "        / (optimal_metric[0] - optimal_metric[1])\n",
    "    )\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=5 n=12 seed=0 initial_ar=0.6673376823128023\n",
      "    optimal_value=9.836361345717636 exact_optimal_value=9.836361345717636 ar=0.6826008119702193\n",
      "p=5 n=12 seed=1 initial_ar=0.7480974832087219\n",
      "    optimal_value=4.783605218990238 exact_optimal_value=4.783605218990238 ar=0.7629046566237015\n",
      "p=5 n=12 seed=2 initial_ar=0.763407497979244\n",
      "    optimal_value=8.638649030606658 exact_optimal_value=8.638649030606658 ar=0.7767236566401157\n",
      "p=5 n=12 seed=3 initial_ar=0.8101468585940048\n",
      "    optimal_value=3.9541034091279883 exact_optimal_value=3.9541034091279883 ar=0.8153836388985273\n",
      "p=5 n=12 seed=4 initial_ar=0.8190151512316447\n",
      "    optimal_value=6.415603080070948 exact_optimal_value=6.415603080070948 ar=0.8258459307862607\n",
      "p=5 n=12 seed=5 initial_ar=0.7709443695603642\n",
      "    optimal_value=6.999744897812005 exact_optimal_value=6.999744897812005 ar=0.7771986811367316\n",
      "p=5 n=12 seed=6 initial_ar=0.7255243095797446\n",
      "    optimal_value=5.740526167543512 exact_optimal_value=5.740526167543512 ar=0.7461470773228223\n",
      "p=5 n=12 seed=7 initial_ar=0.6179212101672594\n",
      "    optimal_value=12.749157599862151 exact_optimal_value=12.749157599862151 ar=0.6334538332575597\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m initial_ar \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seed_pool):\n\u001b[0;32m---> 21\u001b[0m     instance, precomputed_energies \u001b[38;5;241m=\u001b[39m \u001b[43mload_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     instances\u001b[38;5;241m.\u001b[39mappend((instance, precomputed_energies))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m problem \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[1], line 304\u001b[0m, in \u001b[0;36mload_problem\u001b[0;34m(problem, n, seed)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_maxcut_problem(n, seed)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m problem \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_po_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 342\u001b[0m, in \u001b[0;36mload_po_problem\u001b[0;34m(n, seed)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_po_problem\u001b[39m(n, seed):\n\u001b[1;32m    341\u001b[0m     k \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 342\u001b[0m     po_problem \u001b[38;5;241m=\u001b[39m \u001b[43mget_real_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     means_in_spins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    344\u001b[0m         [\n\u001b[1;32m    345\u001b[0m             po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m][i] \u001b[38;5;241m-\u001b[39m po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcov\u001b[39m\u001b[38;5;124m\"\u001b[39m][i, :])\n\u001b[1;32m    346\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    347\u001b[0m         ]\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\n\u001b[1;32m    350\u001b[0m         np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean(((po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcov\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()))\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean((means_in_spins\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()))\n\u001b[1;32m    352\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[1], line 283\u001b[0m, in \u001b[0;36mget_real_problem\u001b[0;34m(N, K, q, seed, pre)\u001b[0m\n\u001b[1;32m    281\u001b[0m po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m q\n\u001b[1;32m    282\u001b[0m po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m], po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcov\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m po_problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pre\n\u001b[1;32m    285\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 250\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(N, seed, real)\u001b[0m\n\u001b[1;32m    248\u001b[0m     start_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-28\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_portfolio_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# tickers=[\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#     stock_symbols[i] for i in rng.choice(len(stock_symbols), size=N, replace=False)\u001b[39;49;00m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ],\u001b[39;49;00m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtickers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstock_symbols\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# data = YahooDataProvider(\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m#     tickers=stock_symbols[:N],\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m#     start=datetime.datetime(2020, 1, 1),\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m#     end=datetime.datetime(2020, 1, 30),\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m#     # end=datetime.datetime(2021, 1, 1),\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    269\u001b[0m data\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[0;32mIn[1], line 138\u001b[0m, in \u001b[0;36mcreate_portfolio_instance\u001b[0;34m(start_date, end_date, num_assets, return_dtype, log_returns, tickers, sort_by_avg_volume, seed)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m tickers:\n\u001b[1;32m    137\u001b[0m     ticker \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(symbol)\n\u001b[0;32m--> 138\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mticker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    141\u001b[0m         invalid_ticker_symbols\u001b[38;5;241m.\u001b[39mappend(symbol)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/shot-frugal/lib/python3.11/site-packages/yfinance/utils.py:103\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m--> 103\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/shot-frugal/lib/python3.11/site-packages/yfinance/base.py:334\u001b[0m, in \u001b[0;36mTickerBase.history\u001b[0;34m(self, period, interval, start, end, prepost, actions, auto_adjust, back_adjust, repair, keepna, proxy, rounding, timeout, raise_errors)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quotes\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m--> 334\u001b[0m         startDt \u001b[38;5;241m=\u001b[39m \u001b[43mquotes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dividends \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m             dividends \u001b[38;5;241m=\u001b[39m dividends\u001b[38;5;241m.\u001b[39mloc[startDt:]\n",
      "File \u001b[0;32mtimestamps.pyx:2126\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.floor\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimestamps.pyx:1910\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp._round\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:4542\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:1022\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.Tick.__mul__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/shot-frugal/lib/python3.11/site-packages/numpy/core/numeric.py:2375\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2373\u001b[0m yfin \u001b[38;5;241m=\u001b[39m isfinite(y)\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xfin) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(yfin):\n\u001b[0;32m-> 2375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwithin_tol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2377\u001b[0m     finite \u001b[38;5;241m=\u001b[39m xfin \u001b[38;5;241m&\u001b[39m yfin\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/shot-frugal/lib/python3.11/site-packages/numpy/core/numeric.py:2356\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[1;32m   2355\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 2356\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m less_equal(\u001b[38;5;28mabs\u001b[39m(x\u001b[38;5;241m-\u001b[39my), atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mabs\u001b[39m(y))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nlopt\n",
    "from qokit.parameter_utils import get_fixed_gamma_beta, get_sk_gamma_beta\n",
    "\n",
    "\n",
    "simulator = \"python\"\n",
    "problem = \"po\"\n",
    "p = 5\n",
    "qubit_pool = [12]\n",
    "method = \"LN_COBYLA\"\n",
    "seed_pool = list(range(60))\n",
    "budget = 10000\n",
    "maxfev = 2 * p + 1 + 3 \n",
    "shots = budget // maxfev\n",
    "rhobeg= 0.1\n",
    "\n",
    "for i, n in enumerate(qubit_pool):\n",
    "    instances = []\n",
    "    results = {}\n",
    "    initial_ar = []\n",
    "    for j, seed in enumerate(seed_pool):\n",
    "        instance, precomputed_energies = load_problem(problem, n, seed)\n",
    "        instances.append((instance, precomputed_energies))\n",
    "        if problem == \"po\":\n",
    "            sense = 1\n",
    "            beta_scaling = 8\n",
    "            # initial_point = [-1.24727193, 1.04931211 * 8]\n",
    "            gamma, beta = get_sk_gamma_beta(p)\n",
    "            minval, maxval = instance[\"feasible_min\"], instance[\"feasible_max\"]\n",
    "        elif problem == \"skmodel\":\n",
    "            sense = -1\n",
    "            beta_scaling = 4\n",
    "            gamma, beta = get_sk_gamma_beta(p)\n",
    "            minval, maxval = np.min(precomputed_energies), np.max(\n",
    "                precomputed_energies\n",
    "            )\n",
    "        else:\n",
    "            sense = -1\n",
    "            beta_scaling = 4\n",
    "            gamma, beta, ar = get_fixed_gamma_beta(3, p, True)\n",
    "            gamma, beta = np.array(gamma), np.array(beta)\n",
    "            minval, maxval = np.min(precomputed_energies), np.max(\n",
    "                precomputed_energies\n",
    "            )\n",
    "        beta *= beta_scaling\n",
    "        initial_point = np.concatenate((gamma, beta))\n",
    "\n",
    "        eval_func = get_evaluate_energy(\n",
    "            instance,\n",
    "            precomputed_energies,\n",
    "            p,\n",
    "            objective=\"expectation\",\n",
    "            simulator=simulator,\n",
    "        )\n",
    "        initial_ar = eval_point(initial_point, eval_func, (minval, maxval), sense)\n",
    "        print(f\"{p=} {n=} {seed=} {initial_ar=}\", flush=True)\n",
    "\n",
    "        def objective_wrapper(params: Sequence[float], gradient: NDArray[np.float_]) -> float:\n",
    "            if gradient.size > 0:\n",
    "                raise NotImplementedError()\n",
    "            return eval_func(params) * sense\n",
    "\n",
    "        optimizer = nlopt.opt(method, len(initial_point))\n",
    "        optimizer.set_ftol_rel(1e-13)\n",
    "        optimizer.set_maxeval(int(maxfev))\n",
    "        optimizer.set_initial_step(rhobeg)\n",
    "        optimizer.set_min_objective(objective_wrapper)\n",
    "        optimal_params = optimizer.optimize(np.array(initial_point))\n",
    "        optimal_value = optimizer.last_optimum_value() * sense\n",
    "        num_fun_evals = optimizer.get_numevals()\n",
    "        exact_optimal_value = eval_func(optimal_params)\n",
    "        ar = eval_point(optimal_params, eval_func, (minval, maxval), sense)\n",
    "        print(f\"    {optimal_value=} {exact_optimal_value=} {ar=}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QAOA-Simulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
