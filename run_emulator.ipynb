{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from time import sleep\n",
    "from typing import Any, Literal\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from qokit.maxcut import maxcut_obj, get_adjacency_matrix\n",
    "from qokit.qaoa_objective_maxcut import get_qaoa_maxcut_objective\n",
    "from qokit.qaoa_objective_portfolio import get_qaoa_portfolio_objective\n",
    "from qokit.utils import precompute_energies\n",
    "from qokit.portfolio_optimization import portfolio_brute_force\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def create_portfolio_instance(\n",
    "    start_date: str = \"2015-01-01\",\n",
    "    end_date: str = \"2019-12-31\",\n",
    "    num_assets: int = 0,\n",
    "    return_dtype: str = \"numpy\",\n",
    "    log_returns: bool = False,\n",
    "    tickers: list | None = None,\n",
    "    sort_by_avg_volume: bool = False,\n",
    "    seed: int = 42,\n",
    ") -> (\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "    | tuple[pd.core.frame.DataFrame, pd.core.frame.DataFrame]\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------------\n",
    "        start_date (str): The starting date\n",
    "        end_date (str): The ending date\n",
    "        num_assets (int): The number of assets\n",
    "\n",
    "\n",
    "        Optional:\n",
    "        return_dtype (str): The return datatype for the covariance matrix\n",
    "                     This is either numpy or panda\n",
    "\n",
    "        tickers (list): The list of ticker symbols. If this is not provided, you will get\n",
    "        the targets and covariance for the random tickers and you can read the\n",
    "        symbols via accessing the covariance as a pandas dataframe\n",
    "\n",
    "        log_returns: If we want the log returns instead of just returns\n",
    "\n",
    "    -------------------\n",
    "    Returns\n",
    "    ---------\n",
    "    List(returns, covariance) : type List(np.array, np.array or pd.dataframe)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (\n",
    "        return_dtype == \"numpy\"\n",
    "        or return_dtype == \"np\"\n",
    "        or return_dtype == \"pd\"\n",
    "        or return_dtype == \"pandas\"\n",
    "    ):\n",
    "        pass\n",
    "    else:\n",
    "        # print(return_dtype)\n",
    "        raise ValueError(\n",
    "            \"The return dtype should be either (numpy) or (np) or pandas or (pd)\"\n",
    "        )\n",
    "\n",
    "    if tickers is None:\n",
    "        # If the user doesn't provide the ticker symbols, we sort by average trading volume and just\n",
    "        # give the data for the number of assets provided\n",
    "\n",
    "        # Download data for the time period\n",
    "        sp500_tickers = pd.read_html(\n",
    "            \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "        )[0]\n",
    "\n",
    "        ticker_symbols = sp500_tickers[\"Symbol\"].tolist()\n",
    "\n",
    "        if num_assets > 0 and not sort_by_avg_volume:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            random_tickers = rng.choice(\n",
    "                len(ticker_symbols), size=num_assets, replace=False\n",
    "            )\n",
    "\n",
    "            top_N_ticker_symbols = np.array(ticker_symbols)[random_tickers].tolist()\n",
    "\n",
    "        else:\n",
    "            top_N_ticker_symbols = ticker_symbols\n",
    "\n",
    "        # Retrieve historical price data for each ticker symbol\n",
    "        stock_data = {}\n",
    "\n",
    "        invalid_ticker_symbols = []\n",
    "\n",
    "        for symbol in top_N_ticker_symbols:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "            if data.empty:\n",
    "                ### Removing the ticker symbols that are invalid\n",
    "                invalid_ticker_symbols.append(symbol)\n",
    "            else:\n",
    "                stock_data[symbol] = data\n",
    "\n",
    "        if sort_by_avg_volume or num_assets == 0:\n",
    "            # Calculate average trading volume for each stock\n",
    "            average_volumes = {}\n",
    "            for symbol, data in stock_data.items():\n",
    "                average_volume = data[\"Volume\"].mean()\n",
    "                average_volumes[symbol] = average_volume\n",
    "\n",
    "            # Sort the stocks based on average trading volume\n",
    "            sorted_stocks = sorted(\n",
    "                average_volumes.items(), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "\n",
    "            # Extract the ticker symbols from the sorted list\n",
    "            ticker_list = [tick[0] for tick in sorted_stocks]\n",
    "\n",
    "            if num_assets > 0:\n",
    "                top_N_ticker_symbols = ticker_list[:num_assets]\n",
    "\n",
    "    ### This is if we are given a set of tickers\n",
    "    ### Then just download data for these, and compute covariance matrices and return vector\n",
    "\n",
    "    else:\n",
    "        num_assets = len(tickers)\n",
    "        # Retrieve historical price data for each ticker symbol\n",
    "        stock_data = {}\n",
    "\n",
    "        invalid_ticker_symbols = []\n",
    "\n",
    "        for symbol in tickers:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            while True:\n",
    "                data = ticker.history(start=start_date, end=end_date)\n",
    "                if not data.empty:\n",
    "                    stock_data[symbol] = data\n",
    "                    break\n",
    "                sleep(2)\n",
    "\n",
    "        top_N_ticker_symbols = tickers\n",
    "\n",
    "    top_N_ticker_symbols = list(stock_data.keys())\n",
    "\n",
    "    ### List of dataframes with the closing prices\n",
    "    list_df_close = [stock_data[symbol][\"Close\"] for symbol in top_N_ticker_symbols]\n",
    "\n",
    "    df_close = pd.concat(list_df_close, axis=1, keys=top_N_ticker_symbols)\n",
    "\n",
    "    ### Drop the ones with rows with NaN values\n",
    "    df_close = df_close.dropna(axis=1)\n",
    "    df_close = df_close.dropna(axis=0)\n",
    "\n",
    "    if not log_returns:\n",
    "        df_returns = df_close.pct_change()  # .dropna( )\n",
    "\n",
    "        #### Drop the first row since we have NaN's\n",
    "        df_returns = df_returns.iloc[1:]\n",
    "\n",
    "        df_mean_returns = df_returns.mean(axis=0)\n",
    "\n",
    "        cov_matrix = df_returns.cov()\n",
    "\n",
    "        if return_dtype in (\"pandas\", \"pd\"):\n",
    "            return [df_mean_returns, cov_matrix]\n",
    "        else:\n",
    "            return [df_mean_returns.to_numpy(), cov_matrix.to_numpy()]\n",
    "\n",
    "    elif log_returns:\n",
    "        df_logreturns = np.log(df_close / df_close.shift(1)).dropna()\n",
    "        df_meanlog_returns = df_logreturns.mean(axis=0)\n",
    "\n",
    "        cov_matrix = df_logreturns.cov()\n",
    "\n",
    "        if return_dtype in (\"pandas\", \"pd\"):\n",
    "            return [df_meanlog_returns, cov_matrix]\n",
    "\n",
    "        else:\n",
    "            return [df_meanlog_returns.to_numpy(), cov_matrix.to_numpy()]\n",
    "\n",
    "\n",
    "def get_data(N, seed=1, real=False):\n",
    "    \"\"\"\n",
    "    load portofolio data from qiskit-finance (Yahoo)\n",
    "    https://github.com/Qiskit/qiskit-finance/blob/main/docs/tutorials/11_time_series.ipynb\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "\n",
    "    from qiskit_finance.data_providers import RandomDataProvider, YahooDataProvider\n",
    "\n",
    "    tickers = []\n",
    "    for i in range(N):\n",
    "        tickers.append(\"t\" + str(i))\n",
    "    if real is False:\n",
    "        data = RandomDataProvider(\n",
    "            tickers=tickers,\n",
    "            start=datetime.datetime(2016, 1, 1),\n",
    "            end=datetime.datetime(2016, 1, 30),\n",
    "            seed=seed,\n",
    "        )\n",
    "    else:\n",
    "        stock_symbols = [\n",
    "            \"AAPL\",\n",
    "            \"GOOGL\",\n",
    "            \"AMZN\",\n",
    "            \"MSFT\",\n",
    "            \"TSLA\",\n",
    "            \"NFLX\",\n",
    "            \"NVDA\",\n",
    "            \"JPM\",\n",
    "            \"V\",\n",
    "            \"JNJ\",\n",
    "            \"WMT\",\n",
    "            \"PG\",\n",
    "            \"MA\",\n",
    "            \"UNH\",\n",
    "            \"HD\",\n",
    "            \"DIS\",\n",
    "            \"BRK-B\",\n",
    "            \"VZ\",\n",
    "            \"KO\",\n",
    "            \"MRK\",\n",
    "            \"INTC\",\n",
    "            \"CMCSA\",\n",
    "            \"PEP\",\n",
    "            \"PFE\",\n",
    "            \"CSCO\",\n",
    "            \"XOM\",\n",
    "            \"BA\",\n",
    "            \"MCD\",\n",
    "            \"ABBV\",\n",
    "            \"IBM\",\n",
    "            \"GE\",\n",
    "            \"MMM\",\n",
    "        ]\n",
    "\n",
    "        # switch to Atithi's implementation\n",
    "        # rng = np.random.default_rng(seed)\n",
    "        # date = rng.integers(0, 60)\n",
    "\n",
    "        date = seed\n",
    "        year = 2015 + date // 12\n",
    "        month = date % 12 + 1\n",
    "        start_date = f\"{year}-{month}-01\"\n",
    "        end_date = f\"{year}-{month}-28\"\n",
    "        return create_portfolio_instance(\n",
    "            start_date,\n",
    "            end_date,\n",
    "            0,\n",
    "            log_returns=False,\n",
    "            seed=seed,\n",
    "            # tickers=[\n",
    "            #     stock_symbols[i] for i in rng.choice(len(stock_symbols), size=N, replace=False)\n",
    "            # ],\n",
    "            tickers=stock_symbols[:N],\n",
    "        )\n",
    "\n",
    "        # data = YahooDataProvider(\n",
    "        #     tickers=stock_symbols[:N],\n",
    "        #     start=datetime.datetime(2020, 1, 1),\n",
    "        #     end=datetime.datetime(2020, 1, 30),\n",
    "        #     # end=datetime.datetime(2021, 1, 1),\n",
    "        # )\n",
    "\n",
    "    data.run()\n",
    "    # use get_period_return_mean_vector & get_period_return_covariance_matrix to get return!\n",
    "    # https://github.com/Qiskit/qiskit-finance/blob/main/docs/tutorials/01_portfolio_optimization.ipynb\n",
    "    means = data.get_period_return_mean_vector()\n",
    "    cov = data.get_period_return_covariance_matrix()\n",
    "    return means, cov\n",
    "\n",
    "\n",
    "def get_real_problem(N, K, q, seed=1, pre=False):\n",
    "    po_problem = {}\n",
    "    po_problem[\"N\"] = N\n",
    "    po_problem[\"K\"] = K\n",
    "    po_problem[\"q\"] = q\n",
    "    po_problem[\"real\"] = True\n",
    "    po_problem[\"means\"], po_problem[\"cov\"] = get_data(N, seed, real=True)\n",
    "    po_problem[\"pre\"] = pre\n",
    "    scale = 1\n",
    "    if pre == \"constant\":\n",
    "        scale = abs(1 / sum(po_problem[\"means\"]))\n",
    "    elif np.isscalar(pre):\n",
    "        scale = pre\n",
    "\n",
    "    po_problem[\"scale\"] = scale\n",
    "    po_problem[\"means\"] = scale * po_problem[\"means\"]\n",
    "    po_problem[\"cov\"] = scale * po_problem[\"cov\"]\n",
    "\n",
    "    return po_problem\n",
    "\n",
    "\n",
    "def load_problem(\n",
    "    problem: Literal[\"maxcut\", \"po\"], n: int, seed: int\n",
    ") -> tuple[dict[str, Any] | nx.Graph, NDArray[np.float_]]:\n",
    "    if problem == \"maxcut\":\n",
    "        return load_maxcut_problem(n, seed)\n",
    "    if problem == \"po\":\n",
    "        return load_po_problem(n, seed)\n",
    "    raise ValueError(f\"Problem {problem} not recognized\")\n",
    "\n",
    "\n",
    "def sample_gaussian_mixture(\n",
    "    num_samples: int, components: Sequence[dict[str, float]], seed: int\n",
    ") -> NDArray[np.float_]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        component = rng.choice(components, p=[c[\"weight\"] for c in components])\n",
    "        sample = rng.normal(component[\"mean\"], component[\"std_dev\"])\n",
    "        samples.append(sample)\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def load_maxcut_problem(n: int, seed: int) -> tuple[nx.Graph, NDArray[np.float_]]:\n",
    "    g = nx.random_regular_graph(3, n, seed)\n",
    "\n",
    "    # Define the parameters for the Gaussian components\n",
    "    component1 = {\"mean\": 0, \"std_dev\": 1, \"weight\": 0.5}\n",
    "    component2 = {\"mean\": 5, \"std_dev\": 2, \"weight\": 0.3}\n",
    "    component3 = {\"mean\": 10, \"std_dev\": 1, \"weight\": 0.2}\n",
    "    components = [component1, component2, component3]\n",
    "    weights = sample_gaussian_mixture(3 * n // 2, components, seed)\n",
    "    # generate random weights\n",
    "    # weights = np.random.uniform(0, 10, g.number_of_edges())\n",
    "    # rescale following the rule in Eq. 6 of https://arxiv.org/pdf/2305.15201.pdf\n",
    "    weights = weights / np.sqrt(np.mean(weights**2))\n",
    "\n",
    "    for i, (w, v) in enumerate(g.edges):\n",
    "        g.edges[w, v][\"weight\"] = weights[i]\n",
    "\n",
    "    return (\n",
    "        g,\n",
    "        None,\n",
    "    )  # precompute_energies(partial(maxcut_obj, w=get_adjacency_matrix(g)), n)\n",
    "\n",
    "\n",
    "def load_po_problem(n, seed):\n",
    "    k = n // 2\n",
    "    po_problem = get_real_problem(n, k, 0.5, seed, pre=1)\n",
    "    means_in_spins = np.array(\n",
    "        [\n",
    "            po_problem[\"means\"][i] - po_problem[\"q\"] * np.sum(po_problem[\"cov\"][i, :])\n",
    "            for i in range(len(po_problem[\"means\"]))\n",
    "        ]\n",
    "    )\n",
    "    scale = 1 / (\n",
    "        np.sqrt(\n",
    "            np.mean((po_problem[\"q\"] * po_problem[\"cov\"]) ** 2)\n",
    "            + np.mean(means_in_spins**2)\n",
    "        )\n",
    "    )\n",
    "    po_problem[\"scale\"] = scale\n",
    "    po_problem[\"means\"] = scale * po_problem[\"means\"]\n",
    "    po_problem[\"cov\"] = scale * po_problem[\"cov\"]\n",
    "    (\n",
    "        min_constrained,\n",
    "        min_x,\n",
    "        max_constrained,\n",
    "        max_x,\n",
    "        mean_constrained,\n",
    "    ) = portfolio_brute_force(po_problem, True)\n",
    "    po_problem[\"feasible_min\"] = min_constrained\n",
    "    po_problem[\"feasible_max\"] = max_constrained\n",
    "    po_problem[\"feasible_min_x\"] = min_x\n",
    "    po_problem[\"feasible_max_x\"] = max_x\n",
    "    po_problem[\"feasible_mean\"] = mean_constrained\n",
    "\n",
    "    return po_problem, None\n",
    "\n",
    "\n",
    "def get_evaluate_energy(\n",
    "    problem: dict[str, Any] | nx.Graph,\n",
    "    precomputed_energies: NDArray[np.float_],\n",
    "    p: int,\n",
    "    objective: str = \"expectation\",\n",
    "    simulator: str = \"auto\",\n",
    ") -> Callable:\n",
    "    if isinstance(problem, nx.Graph):\n",
    "        beta_scaling = 1 / 4\n",
    "        func = get_qaoa_maxcut_objective(\n",
    "            problem.number_of_nodes(),\n",
    "            p,\n",
    "            problem,\n",
    "            precomputed_energies,\n",
    "            objective=objective,\n",
    "            simulator=simulator,\n",
    "        )\n",
    "    else:\n",
    "        beta_scaling = 1 / 8\n",
    "        func = get_qaoa_portfolio_objective(\n",
    "            problem,\n",
    "            p,\n",
    "            precomputed_energies=precomputed_energies,\n",
    "            objective=objective,\n",
    "            simulator=simulator,\n",
    "        )\n",
    "\n",
    "    def f(params):\n",
    "        params = np.array(params)\n",
    "        params[len(params) // 2 :] *= beta_scaling\n",
    "        return func(params)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def eval_point(point, eval_func, optimal_metric, sense):\n",
    "    mean = eval_func(point)\n",
    "    ar = (\n",
    "        sense\n",
    "        * (sense * mean - optimal_metric[int((sense + 1) / 2)])\n",
    "        / (optimal_metric[0] - optimal_metric[1])\n",
    "    )\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=2 n=20 seed=39 initial_ar=0.8270283644179632\n",
      "[0.97541947 1.79597539 2.22024136 1.17003126]\n",
      "-17.65146927047301\n",
      "[1.97541947 1.79597539 2.22024136 1.17003126]\n",
      "-14.167517768633783\n",
      "[0.97541947 2.79597539 2.22024136 1.17003126]\n",
      "-15.427908891626721\n",
      "[0.97541947 1.79597539 3.22024136 1.17003126]\n",
      "-15.226106310493519\n",
      "[0.97541947 1.79597539 2.22024136 2.17003126]\n",
      "-15.073290590802397\n",
      "[0.33518112 1.38735644 1.77453758 0.69624486]\n",
      "-15.976642367019902\n",
      "[0.65530029 1.59166592 1.99738947 0.93313806]\n",
      "-17.455946594533714\n",
      "    optimal_value=17.65146927047301 exact_optimal_value=-17.65146927047301 ar=0.8270283644179632\n"
     ]
    }
   ],
   "source": [
    "import nlopt\n",
    "from qokit.parameter_utils import get_fixed_gamma_beta, get_sk_gamma_beta\n",
    "\n",
    "\n",
    "simulator = \"python\"\n",
    "problem = \"maxcut\"\n",
    "p = 2\n",
    "qubit_pool = [20]\n",
    "method = \"LN_COBYLA\"\n",
    "# seed_pool = list(range(60))\n",
    "seed_pool = [39]\n",
    "budget = 10000\n",
    "maxfev = 2 * p + 1 + 2\n",
    "shots = budget // maxfev\n",
    "rhobeg = 1.0\n",
    "\n",
    "for i, n in enumerate(qubit_pool):\n",
    "    instances = []\n",
    "    results = {}\n",
    "    initial_ar = []\n",
    "    for j, seed in enumerate(seed_pool):\n",
    "        instance, precomputed_energies = load_problem(problem, n, seed)\n",
    "        instances.append((instance, precomputed_energies))\n",
    "        if problem == \"po\":\n",
    "            sense = 1\n",
    "            beta_scaling = -8\n",
    "            # initial_point = [-1.24727193, 1.04931211 * 8]\n",
    "            gamma, beta = get_sk_gamma_beta(p)\n",
    "            minval, maxval = instance[\"feasible_min\"], instance[\"feasible_max\"]\n",
    "        elif problem == \"skmodel\":\n",
    "            sense = -1\n",
    "            beta_scaling = 4\n",
    "            gamma, beta = get_sk_gamma_beta(p)\n",
    "            minval, maxval = np.min(precomputed_energies), np.max(precomputed_energies)\n",
    "        else:\n",
    "            sense = -1\n",
    "            beta_scaling = 4\n",
    "            gamma, beta, ar = get_fixed_gamma_beta(3, p, True)\n",
    "            gamma, beta = np.array(gamma), np.array(beta)\n",
    "            # minval, maxval = np.min(precomputed_energies), np.max(precomputed_energies)\n",
    "            minval, maxval = -0.2994320493763202, 21.405871048036325\n",
    "        beta *= beta_scaling\n",
    "        initial_point = np.concatenate((gamma, beta))\n",
    "\n",
    "        eval_func = get_evaluate_energy(\n",
    "            instance,\n",
    "            precomputed_energies,\n",
    "            p,\n",
    "            objective=\"expectation\",\n",
    "            simulator=simulator,\n",
    "        )\n",
    "        initial_ar = eval_point(initial_point, eval_func, (minval, maxval), sense)\n",
    "        print(f\"{p=} {n=} {seed=} {initial_ar=}\", flush=True)\n",
    "\n",
    "        def objective_wrapper(\n",
    "            params: Sequence[float], gradient: NDArray[np.float_]\n",
    "        ) -> float:\n",
    "            print(params, flush=True)\n",
    "            if gradient.size > 0:\n",
    "                raise NotImplementedError()\n",
    "            value = eval_func(params)\n",
    "            print(value, flush=True)\n",
    "            return value\n",
    "\n",
    "        optimizer = nlopt.opt(method, len(initial_point))\n",
    "        optimizer.set_ftol_rel(1e-13)\n",
    "        optimizer.set_maxeval(int(maxfev))\n",
    "        optimizer.set_initial_step(rhobeg)\n",
    "        optimizer.set_min_objective(objective_wrapper)\n",
    "        optimal_params = optimizer.optimize(np.array(initial_point))\n",
    "        optimal_value = optimizer.last_optimum_value() * sense\n",
    "        num_fun_evals = optimizer.get_numevals()\n",
    "        exact_optimal_value = eval_func(optimal_params) * sense\n",
    "        ar = eval_point(optimal_params, eval_func, (minval, maxval), sense)\n",
    "        print(f\"    {optimal_value=} {exact_optimal_value=} {ar=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QAOA-Simulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
