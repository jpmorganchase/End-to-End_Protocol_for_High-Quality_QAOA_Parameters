{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from typing import Any, Literal\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from qokit.maxcut import maxcut_obj, get_adjacency_matrix\n",
    "from qokit.qaoa_objective_maxcut import get_qaoa_maxcut_objective\n",
    "from qokit.qaoa_objective_portfolio import get_qaoa_portfolio_objective\n",
    "from qokit.utils import precompute_energies\n",
    "from qokit.portfolio_optimization import get_configuration_cost_kw, kbits\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def create_portfolio_instance(\n",
    "    start_date: str = \"2015-01-01\",\n",
    "    end_date: str = \"2019-12-31\",\n",
    "    num_assets: int = 0,\n",
    "    return_dtype: str = \"numpy\",\n",
    "    log_returns: bool = False,\n",
    "    tickers: list | None = None,\n",
    "    sort_by_avg_volume: bool = False,\n",
    "    seed: int = 42,\n",
    ") -> tuple[np.ndarray, np.ndarray] | tuple[pd.core.frame.DataFrame, pd.core.frame.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------------\n",
    "        start_date (str): The starting date\n",
    "        end_date (str): The ending date\n",
    "        num_assets (int): The number of assets\n",
    "\n",
    "\n",
    "        Optional:\n",
    "        return_dtype (str): The return datatype for the correlation matrix\n",
    "                     This is either numpy or panda\n",
    "\n",
    "        tickers (list): The list of ticker symbols. If this is not provided, you will get\n",
    "        the targets and correlation for the random tickers and you can read the\n",
    "        symbols via accessing the correlation as a pandas dataframe\n",
    "\n",
    "        log_returns: If we want the log returns instead of just returns\n",
    "\n",
    "    -------------------\n",
    "    Returns\n",
    "    ---------\n",
    "    List(returns, correlation) : type List(np.array, np.array or pd.dataframe)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (\n",
    "        return_dtype == \"numpy\"\n",
    "        or return_dtype == \"np\"\n",
    "        or return_dtype == \"pd\"\n",
    "        or return_dtype == \"pandas\"\n",
    "    ):\n",
    "        pass\n",
    "    else:\n",
    "        # print(return_dtype)\n",
    "        raise ValueError(\"The return dtype should be either (numpy) or (np) or pandas or (pd)\")\n",
    "\n",
    "    if tickers is None:\n",
    "        # If the user doesn't provide the ticker symbols, we sort by average trading volume and just\n",
    "        # give the data for the number of assets provided\n",
    "\n",
    "        # Download data for the time period\n",
    "        sp500_tickers = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "        ticker_symbols = sp500_tickers[\"Symbol\"].tolist()\n",
    "\n",
    "        if num_assets > 0 and not sort_by_avg_volume:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            random_tickers = rng.choice(len(ticker_symbols), size=num_assets, replace=False)\n",
    "\n",
    "            top_N_ticker_symbols = np.array(ticker_symbols)[random_tickers].tolist()\n",
    "\n",
    "        else:\n",
    "            top_N_ticker_symbols = ticker_symbols\n",
    "\n",
    "        # Retrieve historical price data for each ticker symbol\n",
    "        stock_data = {}\n",
    "\n",
    "        invalid_ticker_symbols = []\n",
    "\n",
    "        for symbol in top_N_ticker_symbols:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "            if data.empty:\n",
    "                ### Removing the ticker symbols that are invalid\n",
    "                invalid_ticker_symbols.append(symbol)\n",
    "            else:\n",
    "                stock_data[symbol] = data\n",
    "\n",
    "        if sort_by_avg_volume or num_assets == 0:\n",
    "            # Calculate average trading volume for each stock\n",
    "            average_volumes = {}\n",
    "            for symbol, data in stock_data.items():\n",
    "                average_volume = data[\"Volume\"].mean()\n",
    "                average_volumes[symbol] = average_volume\n",
    "\n",
    "            # Sort the stocks based on average trading volume\n",
    "            sorted_stocks = sorted(average_volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # Extract the ticker symbols from the sorted list\n",
    "            ticker_list = [tick[0] for tick in sorted_stocks]\n",
    "\n",
    "            if num_assets > 0:\n",
    "                top_N_ticker_symbols = ticker_list[:num_assets]\n",
    "\n",
    "    ### This is if we are given a set of tickers\n",
    "    ### Then just download data for these, and compute correlation matrices and return vector\n",
    "\n",
    "    else:\n",
    "        num_assets = len(tickers)\n",
    "        # Retrieve historical price data for each ticker symbol\n",
    "        stock_data = {}\n",
    "\n",
    "        invalid_ticker_symbols = []\n",
    "\n",
    "        for symbol in tickers:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            data = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "            if data.empty:\n",
    "                invalid_ticker_symbols.append(symbol)\n",
    "            else:\n",
    "                stock_data[symbol] = data\n",
    "\n",
    "        top_N_ticker_symbols = tickers\n",
    "\n",
    "    top_N_ticker_symbols = list(stock_data.keys())\n",
    "\n",
    "    ### List of dataframes with the closing prices\n",
    "    list_df_close = [stock_data[symbol][\"Close\"] for symbol in top_N_ticker_symbols]\n",
    "\n",
    "    df_close = pd.concat(list_df_close, axis=1, keys=top_N_ticker_symbols)\n",
    "\n",
    "    ### Drop the ones with rows with NaN values\n",
    "    df_close = df_close.dropna(axis=1)\n",
    "    df_close = df_close.dropna(axis=0)\n",
    "\n",
    "    if not log_returns:\n",
    "        df_returns = df_close.pct_change()  # .dropna( )\n",
    "\n",
    "        #### Drop the first row since we have NaN's\n",
    "        df_returns = df_returns.iloc[1:]\n",
    "\n",
    "        # print(df_returns.shape)\n",
    "        df_mean_returns = df_returns.mean(axis=0)\n",
    "\n",
    "        correlation_matrix = df_returns.corr()\n",
    "\n",
    "        if return_dtype in (\"pandas\", \"pd\"):\n",
    "            return [df_mean_returns, correlation_matrix]\n",
    "        else:\n",
    "            return [df_mean_returns.to_numpy(), correlation_matrix.to_numpy()]\n",
    "\n",
    "    elif log_returns:\n",
    "        df_logreturns = np.log(df_close / df_close.shift(1)).dropna()\n",
    "        df_meanlog_returns = df_logreturns.mean(axis=0)\n",
    "\n",
    "        correlation_matrix = df_logreturns.corr()\n",
    "\n",
    "        if return_dtype in (\"pandas\", \"pd\"):\n",
    "            return [df_meanlog_returns, correlation_matrix]\n",
    "\n",
    "        else:\n",
    "            return [df_meanlog_returns.to_numpy(), correlation_matrix.to_numpy()]\n",
    "\n",
    "\n",
    "def get_data(N, seed=1, real=False):\n",
    "    \"\"\"\n",
    "    load portofolio data from qiskit-finance (Yahoo)\n",
    "    https://github.com/Qiskit/qiskit-finance/blob/main/docs/tutorials/11_time_series.ipynb\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "\n",
    "    from qiskit_finance.data_providers import (RandomDataProvider,\n",
    "                                               YahooDataProvider)\n",
    "\n",
    "    tickers = []\n",
    "    for i in range(N):\n",
    "        tickers.append(\"t\" + str(i))\n",
    "    if real is False:\n",
    "        data = RandomDataProvider(\n",
    "            tickers=tickers,\n",
    "            start=datetime.datetime(2016, 1, 1),\n",
    "            end=datetime.datetime(2016, 1, 30),\n",
    "            seed=seed,\n",
    "        )\n",
    "    else:\n",
    "        stock_symbols = [\n",
    "            \"AAPL\",\n",
    "            \"GOOGL\",\n",
    "            \"AMZN\",\n",
    "            \"MSFT\",\n",
    "            \"TSLA\",\n",
    "            \"NFLX\",\n",
    "            \"NVDA\",\n",
    "            \"JPM\",\n",
    "            \"V\",\n",
    "            \"JNJ\",\n",
    "            \"WMT\",\n",
    "            \"PG\",\n",
    "            \"MA\",\n",
    "            \"UNH\",\n",
    "            \"HD\",\n",
    "            \"DIS\",\n",
    "            \"BRK-B\",\n",
    "            \"VZ\",\n",
    "            \"KO\",\n",
    "            \"MRK\",\n",
    "            \"INTC\",\n",
    "            \"CMCSA\",\n",
    "            \"PEP\",\n",
    "            \"PFE\",\n",
    "            \"CSCO\",\n",
    "            \"XOM\",\n",
    "            \"BA\",\n",
    "            \"MCD\",\n",
    "            \"ABBV\",\n",
    "            \"IBM\",\n",
    "            \"GE\",\n",
    "            \"MMM\",\n",
    "        ]\n",
    "\n",
    "        # switch to Atithi's implementation\n",
    "        # rng = np.random.default_rng(seed)\n",
    "        # date = rng.integers(0, 60)\n",
    "        \n",
    "        date = seed\n",
    "        year = 2015 + date // 12\n",
    "        month = date % 12 + 1\n",
    "        start_date = f\"{year}-{month}-01\"\n",
    "        end_date = f\"{year}-{month}-28\"\n",
    "        return create_portfolio_instance(\n",
    "            start_date,\n",
    "            end_date,\n",
    "            0,\n",
    "            log_returns=True,\n",
    "            seed=seed,\n",
    "            # tickers=[\n",
    "            #     stock_symbols[i] for i in rng.choice(len(stock_symbols), size=N, replace=False)\n",
    "            # ],\n",
    "            tickers=stock_symbols[:N]\n",
    "        )\n",
    "\n",
    "        # data = YahooDataProvider(\n",
    "        #     tickers=stock_symbols[:N],\n",
    "        #     start=datetime.datetime(2020, 1, 1),\n",
    "        #     end=datetime.datetime(2020, 1, 30),\n",
    "        #     # end=datetime.datetime(2021, 1, 1),\n",
    "        # )\n",
    "\n",
    "    data.run()\n",
    "    # use get_period_return_mean_vector & get_period_return_covariance_matrix to get return!\n",
    "    # https://github.com/Qiskit/qiskit-finance/blob/main/docs/tutorials/01_portfolio_optimization.ipynb\n",
    "    means = data.get_period_return_mean_vector()\n",
    "    cov = data.get_period_return_covariance_matrix()\n",
    "    return means, cov\n",
    "\n",
    "\n",
    "def get_real_problem(N, K, q, seed=1, pre=False):\n",
    "    po_problem = {}\n",
    "    po_problem[\"N\"] = N\n",
    "    po_problem[\"K\"] = K\n",
    "    po_problem[\"q\"] = q\n",
    "    po_problem[\"real\"] = True\n",
    "    po_problem[\"means\"], po_problem[\"cov\"] = get_data(N, seed, real=True)\n",
    "    po_problem[\"pre\"] = pre\n",
    "    scale = 1\n",
    "    if pre == \"constant\":\n",
    "        scale = abs(1 / sum(po_problem[\"means\"]))\n",
    "    elif np.isscalar(pre):\n",
    "        scale = pre\n",
    "\n",
    "    po_problem[\"scale\"] = scale\n",
    "    po_problem[\"means\"] = scale * po_problem[\"means\"]\n",
    "    po_problem[\"cov\"] = scale * po_problem[\"cov\"]\n",
    "\n",
    "    return po_problem\n",
    "\n",
    "\n",
    "def load_problem(\n",
    "    problem: Literal[\"maxcut\", \"po\"], n: int, seed: int\n",
    ") -> tuple[dict[str, Any] | nx.Graph, NDArray[np.float_]]:\n",
    "    if problem == \"maxcut\":\n",
    "        return load_maxcut_problem(n, seed)\n",
    "    if problem == \"po\":\n",
    "        return load_po_problem(n, seed)\n",
    "    raise ValueError(f\"Problem {problem} not recognized\")\n",
    "\n",
    "\n",
    "def sample_gaussian_mixture(\n",
    "    num_samples: int, components: Sequence[dict[str, float]], seed: int\n",
    ") -> NDArray[np.float_]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        component = rng.choice(components, p=[c[\"weight\"] for c in components])\n",
    "        sample = rng.normal(component[\"mean\"], component[\"std_dev\"])\n",
    "        samples.append(sample)\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def load_maxcut_problem(n: int, seed: int) -> tuple[nx.Graph, NDArray[np.float_]]:\n",
    "    g = nx.random_regular_graph(3, n, seed)\n",
    "\n",
    "    # Define the parameters for the Gaussian components\n",
    "    component1 = {\"mean\": 0, \"std_dev\": 1, \"weight\": 0.5}\n",
    "    component2 = {\"mean\": 5, \"std_dev\": 2, \"weight\": 0.3}\n",
    "    component3 = {\"mean\": 10, \"std_dev\": 1, \"weight\": 0.2}\n",
    "    components = [component1, component2, component3]\n",
    "    weights = sample_gaussian_mixture(3 * n // 2, components, seed)\n",
    "    # generate random weights\n",
    "    # weights = np.random.uniform(0, 10, g.number_of_edges())\n",
    "    # rescale following the rule in Eq. 6 of https://arxiv.org/pdf/2305.15201.pdf\n",
    "    weights = weights / np.sqrt(np.mean(weights**2))\n",
    "\n",
    "    for i, (w, v) in enumerate(g.edges):\n",
    "        g.edges[w, v][\"weight\"] = weights[i]\n",
    "\n",
    "    return g, precompute_energies(partial(maxcut_obj, w=get_adjacency_matrix(g)), n)\n",
    "\n",
    "\n",
    "def load_po_problem(n, seed):\n",
    "    k = n // 2\n",
    "    po_problem = get_real_problem(n, k, 0.5, seed, pre=1)\n",
    "    means_in_spins = np.array(\n",
    "        [\n",
    "            po_problem[\"means\"][i] - po_problem[\"q\"] * np.sum(po_problem[\"cov\"][i, :])\n",
    "            for i in range(len(po_problem[\"means\"]))\n",
    "        ]\n",
    "    )\n",
    "    scale = 1 / (\n",
    "        np.sqrt(np.mean(((po_problem[\"q\"] * po_problem[\"cov\"]) ** 2).flatten()))\n",
    "        + np.sqrt(np.mean((means_in_spins**2).flatten()))\n",
    "    )\n",
    "    po_problem[\"scale\"] = scale\n",
    "    po_problem[\"means\"] = scale * po_problem[\"means\"]\n",
    "    po_problem[\"cov\"] = scale * po_problem[\"cov\"]\n",
    "\n",
    "    min_constrained = float(\"inf\")\n",
    "    max_constrained = float(\"-inf\")\n",
    "    mean_constrained = 0\n",
    "    total_constrained = 0\n",
    "    po_obj = partial(get_configuration_cost_kw, po_problem=po_problem)\n",
    "    for x in tqdm(kbits(n, k)):\n",
    "        curr = po_obj(x)\n",
    "        if curr < min_constrained:\n",
    "            min_constrained = curr\n",
    "            min_x = x\n",
    "        if curr > max_constrained:\n",
    "            max_constrained = curr\n",
    "            max_x = x\n",
    "        mean_constrained += curr\n",
    "        total_constrained += 1.0\n",
    "    mean_constrained /= total_constrained\n",
    "    po_problem[\"feasible_min\"] = min_constrained\n",
    "    po_problem[\"feasible_max\"] = max_constrained\n",
    "    po_problem[\"feasible_min_x\"] = min_x\n",
    "    po_problem[\"feasible_max_x\"] = max_x\n",
    "    po_problem[\"feasible_mean\"] = mean_constrained\n",
    "    # precomputed_energies = get_adjusted_state(\n",
    "    #     precompute_energies_parallel(po_obj, n, 1)\n",
    "    # ).real\n",
    "    # precomputed_energies = precompute_energies_parallel_constrained(po_obj, n, k, 1)\n",
    "\n",
    "    return po_problem, None\n",
    "\n",
    "\n",
    "def get_evaluate_energy(\n",
    "    problem: dict[str, Any] | nx.Graph,\n",
    "    precomputed_energies: NDArray[np.float_],\n",
    "    p: int,\n",
    "    objective: str = \"expectation\",\n",
    "    simulator: str = \"auto\",\n",
    ") -> Callable:\n",
    "    if isinstance(problem, nx.Graph):\n",
    "        beta_scaling = 1 / 4\n",
    "        func = get_qaoa_maxcut_objective(\n",
    "            problem.number_of_nodes(),\n",
    "            p,\n",
    "            problem,\n",
    "            precomputed_energies,\n",
    "            objective=objective,\n",
    "            simulator=simulator,\n",
    "        )\n",
    "    else:\n",
    "        beta_scaling = 1 / 8\n",
    "        func = get_qaoa_portfolio_objective(\n",
    "            problem,\n",
    "            p,\n",
    "            precomputed_energies=precomputed_energies,\n",
    "            objective=objective,\n",
    "            simulator=simulator,\n",
    "        )\n",
    "\n",
    "    def f(params):\n",
    "        params = np.array(params)\n",
    "        params[len(params)//2:] *= beta_scaling\n",
    "        return func(params)\n",
    "\n",
    "    return f\n",
    "\n",
    "def eval_point(point, eval_func, optimal_metric, sense):\n",
    "    mean = eval_func(point)\n",
    "    print(mean, optimal_metric)\n",
    "    ar = (\n",
    "        sense\n",
    "        * (mean - optimal_metric[int((sense + 1) / 2)])\n",
    "        / (optimal_metric[0] - optimal_metric[1])\n",
    "    )\n",
    "    return ar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 40175.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1434963997343126 (8.257935532472931, 13.230958754306613)\n",
      "p=5 n=12 seed=0 initial_ar=2.0284366077930347\n",
      "3.103266582722616 (8.257935532472931, 13.230958754306613)\n",
      "    optimal_value=3.103266582722616 exact_optimal_value=3.103266582722616 ar=2.0365262175167675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 27314.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8429486633661747 (3.6740844594424096, 8.353774322523751)\n",
      "p=5 n=12 seed=1 initial_ar=0.963915513877115\n",
      "3.8193842161727405 (3.6740844594424096, 8.353774322523751)\n",
      "    optimal_value=3.8193842161727405 exact_optimal_value=3.8193842161727405 ar=0.9689509858598497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 36955.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3387880847544396 (6.9437955236348, 14.534529996640815)\n",
      "p=5 n=12 seed=2 initial_ar=1.474922084509793\n",
      "3.2747812146568434 (6.9437955236348, 14.534529996640815)\n",
      "    optimal_value=3.2747812146568434 exact_optimal_value=3.2747812146568434 ar=1.4833543212485718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 17390.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.841604931616181 (2.6938480088816994, 9.520182126564562)\n",
      "p=5 n=12 seed=3 initial_ar=0.8318633540422019\n",
      "3.7879146719265373 (2.6938480088816994, 9.520182126564562)\n",
      "    optimal_value=3.7879146719265373 exact_optimal_value=3.7879146719265373 ar=0.8397285213141298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 26365.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5717029604498736 (4.955000530636246, 13.34169871623061)\n",
      "p=5 n=12 seed=4 initial_ar=1.1649394719560113\n",
      "3.5093896081404106 (4.955000530636246, 13.34169871623061)\n",
      "    optimal_value=3.5093896081404106 exact_optimal_value=3.5093896081404106 ar=1.1723694939897717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 25208.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4223434085014506 (5.104338338561946, 13.611485507429583)\n",
      "p=5 n=12 seed=5 initial_ar=1.197715508697892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mset_initial_step(rhobeg)\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mset_min_objective(objective_wrapper)\n\u001b[0;32m---> 65\u001b[0m optimal_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_point\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m optimal_value \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mlast_optimum_value() \u001b[38;5;241m*\u001b[39m sense\n\u001b[1;32m     67\u001b[0m num_fun_evals \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mget_numevals()\n",
      "File \u001b[0;32m~/miniconda3/envs/QAOA-Simulator/lib/python3.10/site-packages/nlopt/nlopt.py:335\u001b[0m, in \u001b[0;36mopt.optimize\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nlopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m, in \u001b[0;36mobjective_wrapper\u001b[0;34m(params, gradient)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meval_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sense\n",
      "Cell \u001b[0;32mIn[3], line 410\u001b[0m, in \u001b[0;36mget_evaluate_energy.<locals>.f\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    408\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(params)\n\u001b[1;32m    409\u001b[0m params[\u001b[38;5;28mlen\u001b[39m(params)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m beta_scaling\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jpmc-argonne-quantum-optimization/qokit/qaoa_objective.py:202\u001b[0m, in \u001b[0;36mget_qaoa_objective.<locals>.f\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    201\u001b[0m     gamma, beta \u001b[38;5;241m=\u001b[39m qokit\u001b[38;5;241m.\u001b[39mparameter_utils\u001b[38;5;241m.\u001b[39mconvert_to_gamma_beta(\u001b[38;5;241m*\u001b[39margs, parameterization\u001b[38;5;241m=\u001b[39mparameterization)\n\u001b[0;32m--> 202\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_qaoa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trotters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trotters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    204\u001b[0m     probs \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mget_probabilities(result) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(obj \u001b[38;5;129;01min\u001b[39;00m objective \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverlap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jpmc-argonne-quantum-optimization/qokit/fur/python/qaoa_simulator.py:54\u001b[0m, in \u001b[0;36mQAOAFastSimulatorPythonBase.simulate_qaoa\u001b[0;34m(self, gammas, betas, sv0, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03msimulator QAOA circuit using FUR\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m@param gammas parameters for the phase separating layers\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m@return statevector or vector of probabilities\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m sv \u001b[38;5;241m=\u001b[39m sv0\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m sv0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_sv0\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_qaoa\u001b[49m\u001b[43m(\u001b[49m\u001b[43msv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sv\n",
      "File \u001b[0;32m~/jpmc-argonne-quantum-optimization/qokit/fur/python/qaoa_simulator.py:100\u001b[0m, in \u001b[0;36mQAOAFURXYRingSimulator._apply_qaoa\u001b[0;34m(self, sv, gammas, betas, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_qaoa\u001b[39m(\u001b[38;5;28mself\u001b[39m, sv: np\u001b[38;5;241m.\u001b[39mndarray, gammas: Sequence[\u001b[38;5;28mfloat\u001b[39m], betas: Sequence[\u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     99\u001b[0m     n_trotters \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_trotters\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mapply_qaoa_furxy_ring\u001b[49m\u001b[43m(\u001b[49m\u001b[43msv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hc_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_qubits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trotters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trotters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jpmc-argonne-quantum-optimization/qokit/fur/python/qaoa_fur.py:38\u001b[0m, in \u001b[0;36mapply_qaoa_furxy_ring\u001b[0;34m(sv, gammas, betas, hc_diag, n_qubits, n_trotters)\u001b[0m\n\u001b[1;32m     36\u001b[0m sv \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39mj \u001b[38;5;241m*\u001b[39m gamma \u001b[38;5;241m*\u001b[39m hc_diag)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_trotters):\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mfurxy_ring\u001b[49m\u001b[43m(\u001b[49m\u001b[43msv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_trotters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_qubits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jpmc-argonne-quantum-optimization/qokit/fur/python/fur.py:77\u001b[0m, in \u001b[0;36mfurxy_ring\u001b[0;34m(x, theta, n_qubits)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, n_qubits \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m         \u001b[43mfurxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m furxy(x, theta, \u001b[38;5;241m0\u001b[39m, n_qubits \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/jpmc-argonne-quantum-optimization/qokit/fur/python/fur.py:66\u001b[0m, in \u001b[0;36mfurxy\u001b[0;34m(x, theta, q1, q2)\u001b[0m\n\u001b[1;32m     64\u001b[0m     ia \u001b[38;5;241m=\u001b[39m i0 \u001b[38;5;241m|\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m q1)\n\u001b[1;32m     65\u001b[0m     ib \u001b[38;5;241m=\u001b[39m i0 \u001b[38;5;241m|\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m q2)\n\u001b[0;32m---> 66\u001b[0m     x[ia], x[ib] \u001b[38;5;241m=\u001b[39m wa \u001b[38;5;241m*\u001b[39m x[ia] \u001b[38;5;241m+\u001b[39m wb \u001b[38;5;241m*\u001b[39m x[ib], wb \u001b[38;5;241m*\u001b[39m x[ia] \u001b[38;5;241m+\u001b[39m wa \u001b[38;5;241m*\u001b[39m x[ib]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nlopt\n",
    "from qokit.parameter_utils import get_fixed_gamma_beta, get_sk_gamma_beta\n",
    "\n",
    "\n",
    "simulator = \"auto\"\n",
    "problem = \"po\"\n",
    "p = 5\n",
    "qubit_pool = [12]\n",
    "method = \"LN_COBYLA\"\n",
    "seed_pool = list(range(60))\n",
    "budget = 10000\n",
    "maxfev = 2 * p + 1 + 3 \n",
    "shots = budget // maxfev\n",
    "rhobeg= 0.1\n",
    "\n",
    "for i, n in enumerate(qubit_pool):\n",
    "    instances = []\n",
    "    results = {}\n",
    "    initial_ar = []\n",
    "    for j, seed in enumerate(seed_pool):\n",
    "        instance, precomputed_energies = load_problem(problem, n, seed)\n",
    "        instances.append((instance, precomputed_energies))\n",
    "        if problem == \"po\":\n",
    "            sense = 1\n",
    "            # initial_point = [-1.24727193, 1.04931211 * 8]\n",
    "            gamma, beta = get_sk_gamma_beta(p)\n",
    "            gamma, beta = gamma.tolist(), beta.tolist()\n",
    "            minval, maxval = instance[\"feasible_min\"], instance[\"feasible_max\"]\n",
    "        elif problem == \"skmodel\":\n",
    "            sense = -1\n",
    "            gamma, beta = get_sk_gamma_beta(p)\n",
    "            gamma, beta = gamma.tolist(), beta.tolist()\n",
    "            minval, maxval = np.min(precomputed_energies), np.max(\n",
    "                precomputed_energies\n",
    "            )\n",
    "        else:\n",
    "            sense = -1\n",
    "            gamma, beta, ar = get_fixed_gamma_beta(3, p, True)\n",
    "            minval, maxval = np.min(precomputed_energies), np.max(\n",
    "                precomputed_energies\n",
    "            )\n",
    "        beta = [b * 4 for b in beta]\n",
    "        initial_point = gamma + beta\n",
    "\n",
    "        eval_func = get_evaluate_energy(\n",
    "            instance,\n",
    "            precomputed_energies,\n",
    "            p,\n",
    "            objective=\"expectation\",\n",
    "            simulator=simulator,\n",
    "        )\n",
    "        initial_ar = eval_point(initial_point, eval_func, (minval, maxval), sense)\n",
    "        print(f\"{p=} {n=} {seed=} {initial_ar=}\", flush=True)\n",
    "\n",
    "        def objective_wrapper(params: Sequence[float], gradient: NDArray[np.float_]) -> float:\n",
    "            if gradient.size > 0:\n",
    "                raise NotImplementedError()\n",
    "            return eval_func(params) * sense\n",
    "\n",
    "        optimizer = nlopt.opt(method, len(initial_point))\n",
    "        optimizer.set_ftol_rel(1e-13)\n",
    "        optimizer.set_maxeval(int(maxfev))\n",
    "        optimizer.set_initial_step(rhobeg)\n",
    "        optimizer.set_min_objective(objective_wrapper)\n",
    "        optimal_params = optimizer.optimize(np.array(initial_point))\n",
    "        optimal_value = optimizer.last_optimum_value() * sense\n",
    "        num_fun_evals = optimizer.get_numevals()\n",
    "        exact_optimal_value = eval_func(optimal_params)\n",
    "        ar = eval_point(optimal_params, eval_func, (minval, maxval), sense)\n",
    "        print(f\"    {optimal_value=} {exact_optimal_value=} {ar=}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QAOA-Simulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
